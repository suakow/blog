{
  
    
        "post0": {
            "title": "Try audio EDA with Cornell Birdcall Data",
            "content": "From kaggle competition . https://www.kaggle.com/c/birdsong-recognition . Load Data . import pandas as pd . time: 2.49 ms . summary_df = pd.read_csv(work_path + &#39;example_test_audio_summary.csv&#39;) . time: 13.5 ms . meta_df = pd.read_csv(work_path + &#39;example_test_audio_metadata.csv&#39;) . time: 23.3 ms . train_df = pd.read_csv(work_path + &#39;train.csv&#39;) . time: 393 ms . summary_df.head() . filename_seconds birds filename seconds . 0 BLKFR-10-CPL_20190611_093000_5 | gockin mouchi westan | BLKFR-10-CPL | 5 | . 1 BLKFR-10-CPL_20190611_093000_10 | gockin westan | BLKFR-10-CPL | 10 | . 2 BLKFR-10-CPL_20190611_093000_15 | gockin westan | BLKFR-10-CPL | 15 | . 3 BLKFR-10-CPL_20190611_093000_20 | mouchi | BLKFR-10-CPL | 20 | . 4 BLKFR-10-CPL_20190611_093000_25 | mouchi | BLKFR-10-CPL | 25 | . time: 27.4 ms . meta_df.head() . file_id device date hour source ebird_code certainty vox_type time_start time_end channel . 0 BLKFR-10-CPL_20190611_093000 | BLKFR-10-CPL | 20190611 | 93000 | jack | westan | c | call | 0.255394 | 0.858845 | 2 | . 1 ORANGE-7-CAP_20190606_093000 | ORANGE-7-CAP | 20190606 | 93000 | jack | squirrel | c | call | 0.415966 | 1.410334 | 1 | . 2 BLKFR-10-CPL_20190611_093000 | BLKFR-10-CPL | 20190611 | 93000 | jack | gockin | l | call | 0.590725 | 1.944412 | 2 | . 3 BLKFR-10-CPL_20190611_093000 | BLKFR-10-CPL | 20190611 | 93000 | jack | mouchi | c | call | 1.609081 | 2.130985 | 2 | . 4 ORANGE-7-CAP_20190606_093000 | ORANGE-7-CAP | 20190606 | 93000 | jack | brncre | c | song | 2.461655 | 2.746925 | 1 | . time: 36.1 ms . Filter only first 5 rows of these 2 species. . train_df = pd.concat([train_df[train_df[&#39;ebird_code&#39;] == &#39;aldfly&#39;].iloc[:5,:], train_df[train_df[&#39;ebird_code&#39;] == &#39;ameavo&#39;].iloc[:5,:]]).reset_index(drop=True) . time: 29.8 ms . train_df.head() . rating playback_used ebird_code channels date pitch duration filename speed species number_of_notes title secondary_labels bird_seen sci_name location latitude sampling_rate type elevation description bitrate_of_mp3 file_type volume background xc_id url country author primary_label longitude length time recordist license . 0 3.5 | no | aldfly | 1 (mono) | 2013-05-25 | Not specified | 25 | XC134874.mp3 | Not specified | Alder Flycatcher | Not specified | XC134874 Alder Flycatcher (Empidonax alnorum) | [&#39;Empidonax minimus_Least Flycatcher&#39;, &#39;Leioth... | yes | Empidonax alnorum | Grey Cloud Dunes SNA, Washington, Minnesota | 44.793 | 48000 (Hz) | call | 220 m | Two short segments of fairly quiet *pip* calls... | 192000 (bps) | mp3 | Not specified | American Yellow Warbler (Setophaga aestiva); L... | 134874 | https://www.xeno-canto.org/134874 | United States | Jonathon Jongsma | Empidonax alnorum_Alder Flycatcher | -92.962 | Not specified | 8:00 | Jonathon Jongsma | Creative Commons Attribution-ShareAlike 3.0 | . 1 4.0 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 36 | XC135454.mp3 | both | Alder Flycatcher | 1-3 | XC135454 Alder Flycatcher (Empidonax alnorum) | [] | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | At least three birds seen here moving around s... | 128000 (bps) | mp3 | level | NaN | 135454 | https://www.xeno-canto.org/135454 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | . 2 4.0 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 39 | XC135455.mp3 | both | Alder Flycatcher | 1-3 | XC135455 Alder Flycatcher (Empidonax alnorum) | [] | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | At least three birds seen chasing each other a... | 128000 (bps) | mp3 | level | NaN | 135455 | https://www.xeno-canto.org/135455 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | . 3 3.5 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 33 | XC135456.mp3 | both | Alder Flycatcher | 1-3 | XC135456 Alder Flycatcher (Empidonax alnorum) | [&#39;Dumetella carolinensis_Gray Catbird&#39;, &#39;Bomby... | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | img:http://www.flickr.com/photos/madbirder/888... | 128000 (bps) | mp3 | level | Grey Catbird (Dumetella carolinensis); Cedar W... | 135456 | https://www.xeno-canto.org/135456 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | . 4 4.0 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 36 | XC135457.mp3 | level | Alder Flycatcher | 1-3 | XC135457 Alder Flycatcher (Empidonax alnorum) | [] | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | img:http://www.flickr.com/photos/madbirder/888... | 128000 (bps) | mp3 | level | NaN | 135457 | https://www.xeno-canto.org/135457 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | . time: 88.8 ms . EDA . summary_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 153 entries, 0 to 152 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 filename_seconds 153 non-null object 1 birds 114 non-null object 2 filename 153 non-null object 3 seconds 153 non-null int64 dtypes: int64(1), object(3) memory usage: 4.9+ KB time: 10.6 ms . meta_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 255 entries, 0 to 254 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 file_id 255 non-null object 1 device 255 non-null object 2 date 255 non-null int64 3 hour 255 non-null int64 4 source 255 non-null object 5 ebird_code 255 non-null object 6 certainty 255 non-null object 7 vox_type 255 non-null object 8 time_start 255 non-null float64 9 time_end 255 non-null float64 10 channel 255 non-null int64 dtypes: float64(2), int64(3), object(6) memory usage: 22.0+ KB time: 12.5 ms . train_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10 entries, 0 to 9 Data columns (total 35 columns): # Column Non-Null Count Dtype -- -- 0 rating 10 non-null float64 1 playback_used 10 non-null object 2 ebird_code 10 non-null object 3 channels 10 non-null object 4 date 10 non-null object 5 pitch 10 non-null object 6 duration 10 non-null int64 7 filename 10 non-null object 8 speed 10 non-null object 9 species 10 non-null object 10 number_of_notes 10 non-null object 11 title 10 non-null object 12 secondary_labels 10 non-null object 13 bird_seen 10 non-null object 14 sci_name 10 non-null object 15 location 10 non-null object 16 latitude 10 non-null object 17 sampling_rate 10 non-null object 18 type 10 non-null object 19 elevation 10 non-null object 20 description 8 non-null object 21 bitrate_of_mp3 10 non-null object 22 file_type 10 non-null object 23 volume 10 non-null object 24 background 4 non-null object 25 xc_id 10 non-null int64 26 url 10 non-null object 27 country 10 non-null object 28 author 10 non-null object 29 primary_label 10 non-null object 30 longitude 10 non-null object 31 length 10 non-null object 32 time 10 non-null object 33 recordist 10 non-null object 34 license 10 non-null object dtypes: float64(1), int64(2), object(32) memory usage: 2.9+ KB time: 16.3 ms . import seaborn as sns sns.countplot(x=train_df[&#39;ebird_code&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fca669eae80&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; time: 166 ms . import plotly.express as px import geopandas as gpd import shapely . time: 488 ms . displayWorldMapByColumnCount(train_df, target_col=&#39;species&#39;, country_col=&#39;country&#39;) . . . time: 988 ms . displayWorldMapByLatLongWithColumnCount(train_df, lat_col=&#39;latitude&#39;, long_col=&#39;longitude&#39;, target_col=&#39;species&#39;) . /usr/local/lib/python3.6/dist-packages/pyproj/crs/crs.py:53: FutureWarning: &#39;+init=&lt;authority&gt;:&lt;code&gt;&#39; syntax is deprecated. &#39;&lt;authority&gt;:&lt;code&gt;&#39; is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; time: 2.17 s . Audio Signal EDA . This is some features that could extract from audio data. . About librosa lib : https://librosa.org/ . ! pip install --upgrade librosa . Requirement already up-to-date: librosa in /usr/local/lib/python3.6/dist-packages (0.8.0) Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,&gt;=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1) Requirement already satisfied, skipping upgrade: scipy&gt;=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1) Requirement already satisfied, skipping upgrade: decorator&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2) Requirement already satisfied, skipping upgrade: joblib&gt;=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.16.0) Requirement already satisfied, skipping upgrade: numba&gt;=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0) Requirement already satisfied, skipping upgrade: soundfile&gt;=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.10.3.post1) Requirement already satisfied, skipping upgrade: numpy&gt;=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.5) Requirement already satisfied, skipping upgrade: pooch&gt;=1.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.1) Requirement already satisfied, skipping upgrade: audioread&gt;=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8) Requirement already satisfied, skipping upgrade: resampy&gt;=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2) Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from numba&gt;=0.43.0-&gt;librosa) (49.6.0) Requirement already satisfied, skipping upgrade: llvmlite&lt;0.32.0,&gt;=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba&gt;=0.43.0-&gt;librosa) (0.31.0) Requirement already satisfied, skipping upgrade: cffi&gt;=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile&gt;=0.9.0-&gt;librosa) (1.14.2) Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from pooch&gt;=1.0-&gt;librosa) (2.23.0) Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from pooch&gt;=1.0-&gt;librosa) (20.4) Requirement already satisfied, skipping upgrade: appdirs in /usr/local/lib/python3.6/dist-packages (from pooch&gt;=1.0-&gt;librosa) (1.4.4) Requirement already satisfied, skipping upgrade: six&gt;=1.3 in /usr/local/lib/python3.6/dist-packages (from resampy&gt;=0.2.2-&gt;librosa) (1.15.0) Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi&gt;=1.0-&gt;soundfile&gt;=0.9.0-&gt;librosa) (2.20) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;pooch&gt;=1.0-&gt;librosa) (2020.6.20) Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;pooch&gt;=1.0-&gt;librosa) (2.10) Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;pooch&gt;=1.0-&gt;librosa) (1.24.3) Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;pooch&gt;=1.0-&gt;librosa) (3.0.4) Requirement already satisfied, skipping upgrade: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;pooch&gt;=1.0-&gt;librosa) (2.4.7) time: 3.14 s . import librosa import IPython . time: 1.49 ms . train_df[&#39;full_path&#39;] = data_path + train_df[&#39;ebird_code&#39;] + &#39;/&#39; + train_df[&#39;filename&#39;] . time: 5.74 ms . train_df.head() . rating playback_used ebird_code channels date pitch duration filename speed species number_of_notes title secondary_labels bird_seen sci_name location latitude sampling_rate type elevation description bitrate_of_mp3 file_type volume background xc_id url country author primary_label longitude length time recordist license full_path . 0 3.5 | no | aldfly | 1 (mono) | 2013-05-25 | Not specified | 25 | XC134874.mp3 | Not specified | Alder Flycatcher | Not specified | XC134874 Alder Flycatcher (Empidonax alnorum) | [&#39;Empidonax minimus_Least Flycatcher&#39;, &#39;Leioth... | yes | Empidonax alnorum | Grey Cloud Dunes SNA, Washington, Minnesota | 44.793 | 48000 (Hz) | call | 220 m | Two short segments of fairly quiet *pip* calls... | 192000 (bps) | mp3 | Not specified | American Yellow Warbler (Setophaga aestiva); L... | 134874 | https://www.xeno-canto.org/134874 | United States | Jonathon Jongsma | Empidonax alnorum_Alder Flycatcher | -92.962 | Not specified | 8:00 | Jonathon Jongsma | Creative Commons Attribution-ShareAlike 3.0 | /content/drive/Shared drives/Suakaw/Colab Note... | . 1 4.0 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 36 | XC135454.mp3 | both | Alder Flycatcher | 1-3 | XC135454 Alder Flycatcher (Empidonax alnorum) | [] | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | At least three birds seen here moving around s... | 128000 (bps) | mp3 | level | NaN | 135454 | https://www.xeno-canto.org/135454 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | /content/drive/Shared drives/Suakaw/Colab Note... | . 2 4.0 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 39 | XC135455.mp3 | both | Alder Flycatcher | 1-3 | XC135455 Alder Flycatcher (Empidonax alnorum) | [] | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | At least three birds seen chasing each other a... | 128000 (bps) | mp3 | level | NaN | 135455 | https://www.xeno-canto.org/135455 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | /content/drive/Shared drives/Suakaw/Colab Note... | . 3 3.5 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 33 | XC135456.mp3 | both | Alder Flycatcher | 1-3 | XC135456 Alder Flycatcher (Empidonax alnorum) | [&#39;Dumetella carolinensis_Gray Catbird&#39;, &#39;Bomby... | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | img:http://www.flickr.com/photos/madbirder/888... | 128000 (bps) | mp3 | level | Grey Catbird (Dumetella carolinensis); Cedar W... | 135456 | https://www.xeno-canto.org/135456 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | /content/drive/Shared drives/Suakaw/Colab Note... | . 4 4.0 | no | aldfly | 2 (stereo) | 2013-05-27 | both | 36 | XC135457.mp3 | level | Alder Flycatcher | 1-3 | XC135457 Alder Flycatcher (Empidonax alnorum) | [] | yes | Empidonax alnorum | Carver&#39;s Gap Parking area, Roan Mountain Stat... | 36.1065 | 44100 (Hz) | call, song | 1700 m | img:http://www.flickr.com/photos/madbirder/888... | 128000 (bps) | mp3 | level | NaN | 135457 | https://www.xeno-canto.org/135457 | United States | Mike Nelson | Empidonax alnorum_Alder Flycatcher | -82.1106 | 0-3(s) | 08:30 | Mike Nelson | Creative Commons Attribution-NonCommercial-Sha... | /content/drive/Shared drives/Suakaw/Colab Note... | . time: 85.3 ms . Sample audio . IPython.display.Audio(train_df[train_df[&#39;ebird_code&#39;] == &quot;aldfly&quot;].sample(1, random_state = 33)[&#39;full_path&#39;].values[0]) . Your browser does not support the audio element. time: 26.2 ms . test_audio = train_df[&#39;full_path&#39;].values[0] . time: 1.55 ms . IPython.display.Audio(test_audio) . Your browser does not support the audio element. time: 20.3 ms . https://librosa.org/doc/latest/generated/librosa.load.html#librosa.load . y, sr = librosa.load(test_audio, res_type=&quot;kaiser_fast&quot;, mono=True) . /usr/local/lib/python3.6/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead. . time: 1.38 s . y.shape . (562011,) . time: 3.57 ms . sr . 22050 . time: 2.72 ms . print(&#39;Audio shape : %s&#39;%(y.shape)) print(&#39;sampling rate : %s&#39;%(sr)) print(&#39;Audio lenght : %s&#39;%(y.shape[0]/sr)) . Audio shape : 562011 sampling rate : 22050 Audio lenght : 25.488027210884354 time: 3.16 ms . plt.plot(y) . [&lt;matplotlib.lines.Line2D at 0x7fca5b96bcf8&gt;] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; time: 399 ms . import librosa.display sns.set(rc={&#39;figure.figsize&#39;:(10, 4)}) librosa.display.waveplot(y, sr=sr,) . &lt;matplotlib.collections.PolyCollection at 0x7fca551404a8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; time: 336 ms . Spectrogram . http://man.hubwiz.com/docset/LibROSA.docset/Contents/Resources/Documents/generated/librosa.core.stft.html . y_st = librosa.stft(y) y_st_dB = librosa.amplitude_to_db(abs(y_st)) plt.figure(figsize=(12, 4)) librosa.display.specshow(y_st_dB, sr=sr, x_axis=&#39;time&#39;, y_axis=&#39;hz&#39;) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fca550d0f28&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; time: 2.06 s . Mel Spectogram . Mel spectrogram is normal spectrogram but in mel scale in y-axis . y_mel = librosa.feature.melspectrogram(y) y_mel_db = librosa.amplitude_to_db(y_mel) plt.figure(figsize=(12, 4)) librosa.display.specshow(y_mel_db, sr=sr, x_axis=&#39;time&#39;, y_axis=&#39;hz&#39;) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fca5507ae48&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; time: 601 ms . Zero-crossing rate . The number of soundwave that switch between positive and negative. . zero_y = librosa.zero_crossings(y, pad=False) . time: 9.78 ms . sum(zero_y) . 205882 . time: 1.28 s .",
            "url": "https://suakow.github.io/blog/jupyter/audio/2020/09/02/_09_03_cornell_birdcall_v1_eda.html",
            "relUrl": "/jupyter/audio/2020/09/02/_09_03_cornell_birdcall_v1_eda.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "CIFAR-10 get acc 90 By EfficientNetB5",
            "content": "https://www.kaggle.com/c/cifar-10 . Import Data . ! pip install tensorflow==2.3 . Collecting tensorflow==2.3 Downloading https://files.pythonhosted.org/packages/97/ae/0b08f53498417914f2274cc3b5576d2b83179b0cbb209457d0fde0152174/tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB) |████████████████████████████████| 320.4MB 49kB/s Requirement already satisfied: absl-py&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.9.0) Collecting tensorboard&lt;3,&gt;=2.3.0 Downloading https://files.pythonhosted.org/packages/e9/1b/6a420d7e6ba431cf3d51b2a5bfa06a958c4141e3189385963dc7f6fbffb6/tensorboard-2.3.0-py3-none-any.whl (6.8MB) |████████████████████████████████| 6.8MB 53.7MB/s Requirement already satisfied: wrapt&gt;=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.12.1) Requirement already satisfied: google-pasta&gt;=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.2.0) Collecting tensorflow-estimator&lt;2.4.0,&gt;=2.3.0 Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB) |████████████████████████████████| 460kB 56.2MB/s Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.1.0) Requirement already satisfied: h5py&lt;2.11.0,&gt;=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (2.10.0) Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.4.1) Requirement already satisfied: numpy&lt;1.19.0,&gt;=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.18.5) Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (3.3.0) Requirement already satisfied: keras-preprocessing&lt;1.2,&gt;=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.1.2) Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.15.0) Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.3.3) Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.6.3) Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.34.2) Requirement already satisfied: grpcio&gt;=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.30.0) Requirement already satisfied: protobuf&gt;=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (3.12.2) Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (0.4.1) Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (2.23.0) Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (3.2.2) Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (1.0.1) Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (1.7.0) Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (49.2.0) Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (1.17.2) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (1.3.0) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (1.24.3) Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.6/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (1.7.0) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (4.1.1) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4; python_version &gt;= &#34;3&#34; in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (4.6) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (0.2.8) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (3.1.0) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (3.1.0) Requirement already satisfied: pyasn1&gt;=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa&lt;5,&gt;=3.1.4; python_version &gt;= &#34;3&#34;-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow==2.3) (0.4.8) Installing collected packages: tensorboard, tensorflow-estimator, tensorflow Found existing installation: tensorboard 2.2.2 Uninstalling tensorboard-2.2.2: Successfully uninstalled tensorboard-2.2.2 Found existing installation: tensorflow-estimator 2.2.0 Uninstalling tensorflow-estimator-2.2.0: Successfully uninstalled tensorflow-estimator-2.2.0 Found existing installation: tensorflow 2.2.0 Uninstalling tensorflow-2.2.0: Successfully uninstalled tensorflow-2.2.0 Successfully installed tensorboard-2.3.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 . ! nvidia-smi . Sat Aug 1 13:40:39 2020 +--+ | NVIDIA-SMI 450.57 Driver Version: 418.67 CUDA Version: 10.1 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 Off | 00000000:00:04.0 Off | 0 | | N/A 53C P8 10W / 70W | 0MiB / 15079MiB | 0% Default | | | | ERR! | +-+-+-+ +--+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +--+ . ! pip install ipython-autotime %load_ext autotime . Collecting ipython-autotime Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2 Building wheels for collected packages: ipython-autotime Building wheel for ipython-autotime (setup.py) ... done Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=c9918ff8ee66f1cf5f460c4003736adc6a574230f1e271be48b97c097a682978 Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e Successfully built ipython-autotime Installing collected packages: ipython-autotime Successfully installed ipython-autotime-0.1 . import numpy as np import pickle import tensorflow as tf . time: 1.2 s . tf.__version__ . &#39;2.3.0&#39; . time: 14.2 ms . (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data() . Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz 170500096/170498071 [==============================] - 4s 0us/step time: 6.05 s . X_train.shape . (50000, 32, 32, 3) . time: 3.07 ms . Preprocessing . import tensorflow as tf ImgDatagenProperty = { # &#39;rescale&#39; : 1/255, &#39;rotation_range&#39; : 15, &#39;width_shift_range&#39; : 0.2, &#39;height_shift_range&#39; : 0.2, &#39;shear_range&#39; : 0.2, &#39;zoom_range&#39; : 0.2, &#39;horizontal_flip&#39; : True, # &#39;fill_mode&#39; : &#39;nearest&#39;, &#39;zca_whitening&#39; : True, &#39;preprocessing_function&#39; : tf.keras.applications.efficientnet.preprocess_input, } . time: 2.69 ms . ImgValDatagenProperty = { # &#39;rescale&#39; : 1/255, &#39;preprocessing_function&#39; : tf.keras.applications.efficientnet.preprocess_input, } . time: 1.04 ms . ImgModelProperty = { &#39;img_height&#39; : 32, &#39;img_width&#39; : 32, &#39;num_class&#39; : 10, &#39;epoch&#39; : 60, &#39;batch_size&#39; : 128 } . time: 1.58 ms . import tensorflow as tf train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**ImgDatagenProperty).flow(X_train, y_train, batch_size=ImgModelProperty[&#39;batch_size&#39;], seed=5555, shuffle=True) val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**ImgValDatagenProperty).flow(X_test, y_test, batch_size=ImgModelProperty[&#39;batch_size&#39;], seed=5555, shuffle=True) . time: 195 ms . /usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:337: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`. warnings.warn(&#39;This ImageDataGenerator specifies &#39; . Model . https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB5 . import tensorflow.keras.backend as K K.clear_session() . time: 7.97 ms . import tensorflow as tf def BuildModel(input_dim = (32, 32, 3), n_class = 10) -&gt; tf.keras.Sequential : model = tf.keras.Sequential() model.add(tf.keras.applications.EfficientNetB5(include_top=False, weights=&#39;imagenet&#39;, input_shape=input_dim)) # model.add(tf.keras.layers.GlobalAveragePooling2D()) model.add(tf.keras.layers.Flatten()) # model.add(tf.keras.layers.Dense(128, activation=tf.keras.activations.relu)) # model.add(tf.keras.layers.BatchNormalization()) model.add(tf.keras.layers.Dense(64, activation=tf.keras.activations.relu)) model.add(tf.keras.layers.BatchNormalization()) # model.add(tf.keras.layers.Dense(32, activation=tf.keras.activations.relu)) # model.add(tf.keras.layers.BatchNormalization()) model.add(tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)) # padding_input = tf.keras.layers.ZeroPadding2D(padding=(96, 96), input_shape=input_dim) # pretrained = tf.keras.applications.inception_v3.InceptionV3(include_top=False, weights=&#39;imagenet&#39;)(padding_input) # model = tf.keras.Model(padding_input.input, pretrained) return model . time: 11.5 ms . model = BuildModel() . Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5 115269632/115263384 [==============================] - 2s 0us/step time: 10.9 s . model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= efficientnetb5 (Functional) (None, 1, 1, 2048) 28513527 _________________________________________________________________ flatten (Flatten) (None, 2048) 0 _________________________________________________________________ dense (Dense) (None, 64) 131136 _________________________________________________________________ batch_normalization (BatchNo (None, 64) 256 _________________________________________________________________ dense_1 (Dense) (None, 10) 650 ================================================================= Total params: 28,645,569 Trainable params: 28,472,698 Non-trainable params: 172,871 _________________________________________________________________ time: 36.9 ms . model.compile( optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.sparse_categorical_accuracy] ) . time: 25.4 ms . import tensorflow as tf red = tf.keras.callbacks.ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.5, patience=2, verbose=1, mode=&#39;auto&#39;, min_lr=1e-7) . time: 1.57 ms . %load_ext tensorboard ! rm -rf ./logs/ . time: 1.72 s . import tensorflow as tf esb = tf.keras.callbacks.EarlyStopping(monitor = &#39;val_loss&#39;, patience = 5) . time: 1.67 ms . import datetime log_dir = &#39;logs/fit/&#39; + datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;) tsb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1) . time: 200 ms . model.fit( train_datagen, epochs=ImgModelProperty[&#39;epoch&#39;], steps_per_epoch=len(X_train) / ImgModelProperty[&#39;batch_size&#39;], validation_data=val_datagen, callbacks=[red, tsb, esb], ) . /usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn&#39;t been fit on any training data. Fit it first by calling `.fit(numpy_data)`. warnings.warn(&#39;This ImageDataGenerator specifies &#39; /usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:739: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn&#39;t been fit on any training data. Fit it first by calling `.fit(numpy_data)`. warnings.warn(&#39;This ImageDataGenerator specifies &#39; . Epoch 1/60 1/390 [..............................] - ETA: 0s - loss: 3.0171 - sparse_categorical_accuracy: 0.0781WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01. Instructions for updating: use `tf.profiler.experimental.stop` instead. 2/390 [..............................] - ETA: 2:10 - loss: 2.9907 - sparse_categorical_accuracy: 0.0977WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1780s vs `on_train_batch_end` time: 0.4917s). Check your callbacks. 391/390 [==============================] - 67s 171ms/step - loss: 1.2835 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.9214 - val_sparse_categorical_accuracy: 0.7160 Epoch 2/60 391/390 [==============================] - 62s 159ms/step - loss: 0.7646 - sparse_categorical_accuracy: 0.7374 - val_loss: 0.6662 - val_sparse_categorical_accuracy: 0.7802 Epoch 3/60 391/390 [==============================] - 62s 159ms/step - loss: 0.6412 - sparse_categorical_accuracy: 0.7818 - val_loss: 0.5763 - val_sparse_categorical_accuracy: 0.8128 Epoch 4/60 391/390 [==============================] - 63s 162ms/step - loss: 0.5779 - sparse_categorical_accuracy: 0.8039 - val_loss: 0.5785 - val_sparse_categorical_accuracy: 0.8135 Epoch 5/60 391/390 [==============================] - 63s 161ms/step - loss: 0.5207 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.4894 - val_sparse_categorical_accuracy: 0.8375 Epoch 6/60 391/390 [==============================] - 63s 162ms/step - loss: 0.4844 - sparse_categorical_accuracy: 0.8332 - val_loss: 0.4586 - val_sparse_categorical_accuracy: 0.8428 Epoch 7/60 391/390 [==============================] - 63s 162ms/step - loss: 0.4514 - sparse_categorical_accuracy: 0.8453 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8594 Epoch 8/60 391/390 [==============================] - 63s 160ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8501 - val_loss: 0.4165 - val_sparse_categorical_accuracy: 0.8638 Epoch 9/60 391/390 [==============================] - 63s 162ms/step - loss: 0.4103 - sparse_categorical_accuracy: 0.8576 - val_loss: 0.3926 - val_sparse_categorical_accuracy: 0.8706 Epoch 10/60 391/390 [==============================] - 63s 161ms/step - loss: 0.3905 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.8452 Epoch 11/60 391/390 [==============================] - ETA: 0s - loss: 0.3809 - sparse_categorical_accuracy: 0.8697 Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257. 391/390 [==============================] - 63s 161ms/step - loss: 0.3809 - sparse_categorical_accuracy: 0.8697 - val_loss: 0.4152 - val_sparse_categorical_accuracy: 0.8632 Epoch 12/60 391/390 [==============================] - 63s 160ms/step - loss: 0.3113 - sparse_categorical_accuracy: 0.8919 - val_loss: 0.3510 - val_sparse_categorical_accuracy: 0.8856 Epoch 13/60 391/390 [==============================] - 62s 159ms/step - loss: 0.2880 - sparse_categorical_accuracy: 0.9003 - val_loss: 0.3543 - val_sparse_categorical_accuracy: 0.8877 Epoch 14/60 391/390 [==============================] - 63s 161ms/step - loss: 0.2675 - sparse_categorical_accuracy: 0.9071 - val_loss: 0.3270 - val_sparse_categorical_accuracy: 0.8928 Epoch 15/60 391/390 [==============================] - 63s 160ms/step - loss: 0.2681 - sparse_categorical_accuracy: 0.9079 - val_loss: 0.3352 - val_sparse_categorical_accuracy: 0.8905 Epoch 16/60 391/390 [==============================] - ETA: 0s - loss: 0.2547 - sparse_categorical_accuracy: 0.9120 Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628. 391/390 [==============================] - 63s 161ms/step - loss: 0.2547 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.8922 Epoch 17/60 391/390 [==============================] - 62s 159ms/step - loss: 0.2193 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3264 - val_sparse_categorical_accuracy: 0.8967 Epoch 18/60 391/390 [==============================] - 62s 160ms/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9303 - val_loss: 0.3115 - val_sparse_categorical_accuracy: 0.8991 Epoch 19/60 391/390 [==============================] - 64s 162ms/step - loss: 0.1896 - sparse_categorical_accuracy: 0.9331 - val_loss: 0.3171 - val_sparse_categorical_accuracy: 0.8993 Epoch 20/60 391/390 [==============================] - ETA: 0s - loss: 0.1843 - sparse_categorical_accuracy: 0.9359 Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814. 391/390 [==============================] - 64s 163ms/step - loss: 0.1843 - sparse_categorical_accuracy: 0.9359 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.9000 Epoch 21/60 391/390 [==============================] - 63s 162ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9420 - val_loss: 0.3095 - val_sparse_categorical_accuracy: 0.9015 Epoch 22/60 391/390 [==============================] - 63s 162ms/step - loss: 0.1548 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.3222 - val_sparse_categorical_accuracy: 0.8991 Epoch 23/60 391/390 [==============================] - ETA: 0s - loss: 0.1486 - sparse_categorical_accuracy: 0.9482 Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05. 391/390 [==============================] - 63s 162ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.3169 - val_sparse_categorical_accuracy: 0.9004 Epoch 24/60 391/390 [==============================] - 63s 162ms/step - loss: 0.1426 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.3063 - val_sparse_categorical_accuracy: 0.9063 Epoch 25/60 391/390 [==============================] - 64s 163ms/step - loss: 0.1349 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.3067 - val_sparse_categorical_accuracy: 0.9043 Epoch 26/60 391/390 [==============================] - ETA: 0s - loss: 0.1350 - sparse_categorical_accuracy: 0.9531 Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05. 391/390 [==============================] - 65s 166ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.9039 Epoch 27/60 391/390 [==============================] - 64s 164ms/step - loss: 0.1294 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.3080 - val_sparse_categorical_accuracy: 0.9048 Epoch 28/60 391/390 [==============================] - ETA: 0s - loss: 0.1268 - sparse_categorical_accuracy: 0.9558 Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05. 391/390 [==============================] - 64s 163ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.9066 Epoch 29/60 391/390 [==============================] - 63s 161ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.3151 - val_sparse_categorical_accuracy: 0.9058 . &lt;tensorflow.python.keras.callbacks.History at 0x7f94affc4320&gt; . time: 31min 8s . %tensorboard --logdir logs/fit . time: 8.09 s . . y_pred = model.predict(val_datagen) . time: 5.84 s . model.evaluate(val_datagen) . 79/79 [==============================] - 4s 44ms/step - loss: 0.3151 - sparse_categorical_accuracy: 0.9058 . [0.31511980295181274, 0.9057999849319458] . time: 3.84 s .",
            "url": "https://suakow.github.io/blog/jupyter/image/tensorflow/2020/09/02/_07_24_cifar10_acc90_EfficientNetB5.html",
            "relUrl": "/jupyter/image/tensorflow/2020/09/02/_07_24_cifar10_acc90_EfficientNetB5.html",
            "date": " • Sep 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://suakow.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://suakow.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://suakow.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Puri Base",
          "content": "Test puri page .",
          "url": "https://suakow.github.io/blog/puri/",
          "relUrl": "/puri/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

}